"""
Therapeutic Chatbot Logic (MVP Version)
--------------------------------------

This module implements a therapeutic chatbot with OpenAI GPT-4 integration.  
It supports:

- Crisis message detection
- GPT-4 response generation
- RAG-enhanced context retrieval
- Conversation continuity
- Robust error handling with graceful degradation
- Fallback responses when APIs fail
- Logging, metrics, and database failure-safe behavior

Enhancements:
- Improved error handling
- More stable API fallback system
- Handles missing DB columns safely (helpful during schema migration)
- Better logging for debugging & observability
"""

import os
import re
import time
import logging
import json
import requests
from typing import List, Dict, Optional

import google
import google.generativeai as genai
from google.api_core import retry
from sqlalchemy.orm import Session

from rag_system_v2 import TherapeuticRAG
from database import (
    get_or_create_user,
    get_active_conversation,
    save_message,
    get_conversation_history
)

logger = logging.getLogger(__name__)


class TherapeuticChatbot:
    """Main chatbot class for handling therapeutic conversations."""

    # Keywords that indicate a psychological crisis
    CRISIS_KEYWORDS = [
        "suicide", "suicidal", "kill myself", "end my life", "want to die",
        "self-harm", "hurt myself", "cutting", "overdose", "no reason to live",
        "better off dead", "hopeless", "can't go on"
    ]

    # Crisis response template
    CRISIS_RESPONSE = (
        "T√¥i hi·ªÉu r·∫±ng b·∫°n ƒëang tr·∫£i qua m·ªôt th·ªùi gian v√¥ c√πng kh√≥ khƒÉn, v√† t√¥i lo l·∫Øng v·ªÅ "
        "s·ª± an to√†n c·ªßa b·∫°n. Cu·ªôc s·ªëng c·ªßa b·∫°n c√≥ √Ω nghƒ©a, v√† c√≥ nh·ªØng ng∆∞·ªùi mu·ªën gi√∫p ƒë·ª° b·∫°n ngay b√¢y gi·ªù.\n\n"
        "**Vui l√≤ng li√™n h·ªá ngay ƒë·ªÉ ƒë∆∞·ª£c h·ªó tr·ª£:**\n\n"
        "üÜò ƒê∆∞·ªùng d√¢y t·ª± t·ª≠ 24/7: 1800 123 456\n"
        "üí¨ T∆∞ v·∫•n kh·ªßng ho·∫£ng: 1900 232 389\n"
        "üåê Trung t√¢m t√¢m l√Ω: G·ªçi 028 3823 0808\n\n"
        "Nh·ªØng d·ªãch v·ª• n√†y mi·ªÖn ph√≠, b·∫£o m·∫≠t, v√† lu√¥n s·∫µn s√†ng 24/7. Nh·ªØng nh√¢n vi√™n t∆∞ v·∫•n ƒë√£ ƒë∆∞·ª£c ƒë√†o t·∫°o s·∫µn s√†ng l·∫Øng nghe.\n\n"
        "N·∫øu b·∫°n ƒëang g·∫∑p nguy hi·ªÉm tr·ª±c ti·∫øp, vui l√≤ng g·ªçi c·∫•p c·ª©u 115 ho·∫∑c ƒë·∫øn ph√≤ng kh√°m c·∫•p c·ª©u g·∫ßn nh·∫•t.\n\n"
        "T√¥i ·ªü ƒë√¢y ƒë·ªÉ h·ªó tr·ª£ b·∫°n v·ªÅ s·ª©c kh·ªèe t√¢m l√Ω, nh∆∞ng nh·ªØng chuy√™n gia t∆∞ v·∫•n chuy√™n nghi·ªáp "
        "ƒë∆∞·ª£c trang b·ªã t·ªët h∆°n ƒë·ªÉ gi√∫p ƒë·ª° nh·ªØng c·∫£m x√∫c tuy·ªát v·ªçng. B·∫°n c√≥ mu·ªën chia s·∫ª ƒëi·ªÅu g√¨ khi·∫øn b·∫°n li√™n h·ªá v·ªõi t√¥i kh√¥ng?"
    )

    def __init__(self, google_api_key: str, rag_system: Optional[TherapeuticRAG] = None):
        """
        Initialize chatbot with Google Gemini API client and optional RAG system.

        Args:
            google_api_key: Google API key for Gemini
            rag_system: Optional RAG instance initialized in server.py
        """
        genai.configure(api_key=google_api_key)
        # Use available models in order of preference
        models_to_try = [
            'gemini-2.5-pro',        # Most capable
            'gemini-2.5-flash',      # Fast and good quality
            'gemini-pro-latest',     # Stable fallback
            'gemini-2.0-flash'       # Older but available
        ]
        self.model = None
        for model_name in models_to_try:
            try:
                self.model = genai.GenerativeModel(model_name)
                logger.info(f"‚úì Using model: {model_name}")
                break
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Model {model_name} not available: {e}")
        
        if self.model is None:
            # Final fallback to gemini-2.5-flash
            self.model = genai.GenerativeModel('gemini-2.5-flash')
            logger.warning("‚ö†Ô∏è Using fallback model gemini-2.5-flash")
        
        self.rag = rag_system
        logger.info("‚úì Model Gemini initialized")

    # -------------------------------------------------------------------------
    # Crisis Detection
    # -------------------------------------------------------------------------

    def detect_crisis(self, message: str) -> bool:
        """Return True if the message contains crisis-related keywords."""
        message_lower = message.lower()
        return any(keyword in message_lower for keyword in self.CRISIS_KEYWORDS)

    # -------------------------------------------------------------------------
    # REST API method (Fallback)
    # -------------------------------------------------------------------------

    def _generate_response_via_rest(self, system_prompt: str, user_message: str) -> Optional[str]:
        """
        Generate response using REST API directly instead of SDK.
        Sometimes bypasses strict filtering that affects SDK calls.
        """
        try:
            # Try GEMINI_API_KEY first, then GOOGLE_API_KEY
            api_key = os.getenv("GEMINI_API_KEY") or os.getenv("GOOGLE_API_KEY")
            if not api_key:
                logger.warning("‚ö†Ô∏è API key (GEMINI_API_KEY or GOOGLE_API_KEY) not set")
                return None

            # Try multiple models in order of preference
            models_to_try = [
                'gemini-2.5-pro',
                'gemini-2.5-flash',
                'gemini-pro-latest',
                'gemini-2.0-flash'
            ]
            
            headers = {"Content-Type": "application/json"}
            
            payload = {
                "contents": [
                    {
                        "role": "user",
                        "parts": [
                            {"text": system_prompt},
                            {"text": user_message}
                        ]
                    }
                ],
                "generationConfig": {
                    "temperature": 0.7,
                    "maxOutputTokens": 10000
                }
            }

            for model_name in models_to_try:
                try:
                    url = f"https://generativelanguage.googleapis.com/v1beta/models/{model_name}:generateContent?key={api_key}"
                    response = requests.post(url, json=payload, headers=headers, timeout=30)
                    
                    if response.status_code == 200:
                        data = response.json()
                        if "candidates" in data and len(data["candidates"]) > 0:
                            candidate = data["candidates"][0]
                            if "content" in candidate and "parts" in candidate["content"]:
                                if len(candidate["content"]["parts"]) > 0:
                                    text = candidate["content"]["parts"][0].get("text", "").strip()
                                    if text:
                                        logger.info(f"‚úì REST API ({model_name}) tr·∫£ v·ªÅ response th√†nh c√¥ng")
                                        return text
                            # Check finish_reason
                            finish_reason = candidate.get("finishReason", "UNKNOWN")
                            logger.warning(f"‚ö†Ô∏è REST API ({model_name}) response b·ªã ch·∫∑n (finish_reason: {finish_reason})")
                    else:
                        logger.debug(f"‚ö†Ô∏è REST API model {model_name} l·ªói {response.status_code}")
                        continue
                except Exception as e:
                    logger.debug(f"‚ö†Ô∏è REST API model {model_name} error: {e}")
                    continue
            
            logger.warning("‚ö†Ô∏è All REST API models blocked or failed")
            return None

        except Exception as e:
            logger.error(f"‚ùå L·ªói REST API: {e}")
            return None

    # User Handling (Safe Mode)
    # -------------------------------------------------------------------------

    def _get_or_create_user_safe(self, db: Session, whatsapp_number: str):
        """
        Safely retrieve or create a user object.
        Avoids breaking when DB columns are missing.

        Returns:
            User object, or a fallback MinimalUser object if DB query fails.
        """
        try:
            user = get_or_create_user(db, whatsapp_number)
            logger.info(f"‚úì Ng∆∞·ªùi d√πng ƒë∆∞·ª£c l·∫•y/t·∫°o: {whatsapp_number}")
            return user

        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Kh√¥ng th·ªÉ l·∫•y/t·∫°o ng∆∞·ªùi d√πng: {e}")

            # Fallback minimal user representation
            class MinimalUser:
                def __init__(self, phone):
                    self.id = hash(phone)
                    self.whatsapp_number = phone
                    self.crisis_flag = False

            return MinimalUser(whatsapp_number)

    # -------------------------------------------------------------------------
    # Response Generation
    # -------------------------------------------------------------------------

    def generate_response(self, db: Session, whatsapp_number: str, user_message: str) -> Dict:
        """
        Generate a therapeutic response using GPT-4 + RAG (if available).

        Returns:
            {
              "response": <string>,
              "is_crisis": <bool>,
              "user_id": <string or None>
            }
        """
        start_time = time.time()

        try:
            # -------------------------
            # 1. Get User (Safe)
            # -------------------------
            user = self._get_or_create_user_safe(db, whatsapp_number)

            # -------------------------
            # 2. Crisis Detection
            # -------------------------
            is_crisis = self.detect_crisis(user_message)

            if is_crisis:
                logger.warning(f"‚ö†Ô∏è Ph√°t hi·ªán n·ªôi dung kh·ªßng ho·∫£ng t·ª´ {whatsapp_number}")

                # Attempt to set crisis flag
                try:
                    if hasattr(user, "crisis_flag"):
                        user.crisis_flag = True
                        db.commit()
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Kh√¥ng th·ªÉ l∆∞u c·ªù kh·ªßng ho·∫£ng: {e}")

                # Save crisis message
                try:
                    conversation = get_active_conversation(db, user.id)
                    crisis_embedding = None

                    if self.rag:
                        try:
                            crisis_embedding = self.rag.create_embedding(self.CRISIS_RESPONSE)
                        except Exception:
                            crisis_embedding = None

                    save_message(
                        db, conversation.id, user.id, "assistant",
                        self.CRISIS_RESPONSE, crisis_embedding
                    )
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Kh√¥ng th·ªÉ l∆∞u tin nh·∫Øn kh·ªßng ho·∫£ng: {e}")

                return {
                    "response": self.CRISIS_RESPONSE,
                    "is_crisis": True,
                    "user_id": str(user.id)
                }

            # -------------------------
            # 3. Normal Conversation Flow
            # -------------------------

            try:
                conversation = get_active_conversation(db, user.id)
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Kh√¥ng th·ªÉ l·∫•y cu·ªôc h·ªôi tho·∫°i: {e}")
                conversation = None

            # Retrieve history
            try:
                if conversation:
                    history_messages = get_conversation_history(db, conversation.id, limit=10)
                    conversation_history = [
                        {"role": m.role, "content": m.content}
                        for m in history_messages
                    ]
                else:
                    conversation_history = []

            except Exception as e:
                logger.warning(f"‚ö†Ô∏è L·ªói khi l·∫•y l·ªãch s·ª≠: {e}")
                conversation_history = []

            # Retrieve RAG context
            relevant_contexts = []
            if self.rag:
                try:
                    relevant_contexts = self.rag.retrieve_relevant_context(
                        db, user_message, k=20
                    )
                except Exception as e:
                    logger.error(f"‚ùå L·ªói khi l·∫•y b·ªëi c·∫£nh RAG: {e}")

            # Build prompt
            try:
                if self.rag:
                    prompt = self.rag.build_prompt_with_context(
                        user_message, relevant_contexts, conversation_history
                    )
                else:
                    prompt = f"You are a compassionate digital wellness therapist. User message: {user_message}"
            except Exception:
                prompt = f"You are a compassionate digital wellness therapist. User message: {user_message}"

            # -------------------------
            # 4. Gemini Response (Retry Logic)
            # -------------------------

            bot_response = None

            for attempt in range(3):
                try:
                    # Build prompt with RAG context if available
                    if relevant_contexts:
                        context_text = "\n".join([f"- {ctx}" for ctx in relevant_contexts])
                        system_prompt = f"""B·∫°n l√† m·ªôt chuy√™n gia t∆∞ v·∫•n. Tr·∫£ l·ªùi c√¢u h·ªèi m·ªôt c√°ch h·ªØu √≠ch, th√¢n thi·ªán v√† t√¥n tr·ªçng.

Th√¥ng tin tham kh·∫£o:
{context_text}

H∆∞·ªõng d·∫´n: H√£y tr·∫£ l·ªùi ng·∫Øn g·ªçn (d∆∞·ªõi 300 t·ª´)."""
                    else:
                        system_prompt = """B·∫°n l√† m·ªôt chuy√™n gia t∆∞ v·∫•n. Tr·∫£ l·ªùi c√¢u h·ªèi m·ªôt c√°ch h·ªØu √≠ch, th√¢n thi·ªán v√† t√¥n tr·ªçng. H√£y tr·∫£ l·ªùi ng·∫Øn g·ªçn (d∆∞·ªõi 300 t·ª´)."""

                    # Use REST API on attempt >= 1 (fallback from SDK failures)
                    if attempt >= 1:
                        logger.info(f"üîÑ Th·ª≠ REST API (l·∫ßn th·ª≠ {attempt + 1})")
                        rest_response = self._generate_response_via_rest(system_prompt, user_message)
                        if rest_response:
                            bot_response = rest_response
                            break
                        else:
                            # REST API also failed, continue to retry
                            if attempt < 2:
                                time.sleep(1)
                            continue

                    # First attempt: use SDK
                    message_history = conversation_history.copy() if conversation_history else []
                    message_history.append({"role": "user", "content": user_message})

                    response = self.model.generate_content(
                        contents=[
                            {"role": "user", "parts": [system_prompt]},
                            {"role": "user", "parts": [user_message]}
                        ],
                        generation_config=genai.types.GenerationConfig(
                            temperature=0.7,
                            max_output_tokens=1000,
                        )
                    )

                    # Check if response has valid content before accessing .text
                    if response and response.candidates and len(response.candidates) > 0:
                        candidate = response.candidates[0]
                        if candidate.content and candidate.content.parts and len(candidate.content.parts) > 0:
                            bot_response = candidate.content.parts[0].text.strip()
                            break
                        else:
                            # Response blocked or empty - try REST API next
                            logger.warning(f"‚ö†Ô∏è Response b·ªã ch·∫∑n ho·∫∑c tr·ªëng (finish_reason: {candidate.finish_reason})")
                            bot_response = None
                    else:
                        logger.warning("‚ö†Ô∏è API tr·∫£ v·ªÅ response kh√¥ng c√≥ candidates")
                        bot_response = None

                except google.generativeai.types.BlockedPromptException as e:
                    logger.warning(f"‚ö†Ô∏è L·ªói b·ªã ch·∫∑n b·ªüi b·ªô l·ªçc an to√†n: {e}")
                    bot_response = "T√¥i ƒë√°nh gi√° cao vi·ªác b·∫°n li√™n h·ªá, nh∆∞ng t√¥i c·∫ßn ti·∫øp c·∫≠n kh√°c. H√£y t·∫≠p trung v√†o h·ªó tr·ª£ c·ª• th·ªÉ b·∫°n ƒëang t√¨m ki·∫øm ngay b√¢y gi·ªù."
                    break

                except Exception as e:
                    logger.error(f"‚ùå L·ªói API Gemini (l·∫ßn th·ª≠ {attempt + 1}): {e}")
                    if attempt < 2:
                        time.sleep(1 + attempt)  # Exponential backoff
                    elif attempt == 2:
                        # Final attempt failed
                        bot_response = None
                        break

            # Fallback response if Gemini fails
            if not bot_response:
                bot_response = self._get_fallback_response(user_message)

            # -------------------------
            # 5. Save Messages
            # -------------------------
            try:
                if conversation:
                    # Save user msg
                    try:
                        user_embed = self.rag.create_embedding(user_message) if self.rag else None
                    except Exception:
                        user_embed = None

                    save_message(
                        db, conversation.id, user.id,
                        "user", user_message, user_embed
                    )

                    # Save bot msg
                    try:
                        bot_embed = self.rag.create_embedding(bot_response) if self.rag else None
                    except Exception:
                        bot_embed = None

                    save_message(
                        db, conversation.id, user.id,
                        "assistant", bot_response, bot_embed
                    )
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Could not save messages: {e}")

            # Completed
            elapsed = time.time() - start_time
            logger.info(f"‚úì Ph·∫£n h·ªìi ƒë∆∞·ª£c t·∫°o trong {elapsed:.2f}s")

            return {
                "response": bot_response,
                "is_crisis": False,
                "user_id": str(user.id)
            }

        except Exception as e:
            logger.error(f"‚ùå L·ªói nghi√™m tr·ªçng: {e}", exc_info=True)

            fallback = (
                "Xin l·ªói ‚Äî T√¥i ƒëang g·∫∑p s·ª± c·ªë k·ªπ thu·∫≠t t·∫°m th·ªùi.\n\n"
                "N·∫øu b·∫°n ƒëang g·∫∑p kh·ªßng ho·∫£ng, vui l√≤ng li√™n h·ªá:\n"
                "- ƒê∆∞·ªùng d√¢y t·ª± t·ª≠ 24/7: 1800 123 456\n"
                "- T∆∞ v·∫•n kh·ªßng ho·∫£ng: 1900 232 389\n\n"
                "Vui l√≤ng th·ª≠ l·∫°i sau m·ªôt l√°t."
            )

            return {
                "response": fallback,
                "is_crisis": False,
                "user_id": None
            }

    # -------------------------------------------------------------------------
    # Fallback Responses
    # -------------------------------------------------------------------------

    def _get_fallback_response(self, user_message: str) -> str:
        """
        Generate contextual fallback if GPT-4 is unavailable.
        """

        text = user_message.lower()

        # Screen time concerns
        if any(word in text for word in ["screen", "phone", "instagram", "tiktok", "social media", "m√†n h√¨nh", "ƒëi·ªán tho·∫°i", "m·∫°ng x√£ h·ªôi"]):
            return (
                "T√¥i hi·ªÉu r·∫±ng b·∫°n lo l·∫Øng v·ªÅ th·ªùi gian s·ª≠ d·ª•ng m√†n h√¨nh. ƒê√¢y l√† m·ªôt k·ªπ thu·∫≠t nhanh:\n\n"
                "H√£y th·ª≠ ph∆∞∆°ng ph√°p **B·ªën Qu√¢n Xanh** ‚Äî b·∫Øt ƒë·∫ßu v·ªõi *Nh·∫≠n Th·ª©c*. L∆∞u √Ω c√°c m√¥ h√¨nh s·ª≠ d·ª•ng ƒëi·ªán tho·∫°i "
                "c·ªßa b·∫°n m√† kh√¥ng ph√°n x√©t. ƒêi·ªÅu g√¨ th∆∞·ªùng k√≠ch ho·∫°t b·∫°n s·ª≠ d·ª•ng ƒëi·ªán tho·∫°i? üì±\n\n"
                "B·∫°n c√≥ th·ªÉ x√°c ƒë·ªãnh ƒë∆∞·ª£c m·ªôt k√≠ch ho·∫°t ngay b√¢y gi·ªù kh√¥ng?"
            )

        # Stress / anxiety
        if any(word in text for word in ["stress", "anxiety", "worried", "anxious", "cƒÉng th·∫≥ng", "lo √¢u", "lo l·∫Øng", "s·ª£ h√£i"]):
            return (
                "Nghe c√≥ v·∫ª b·∫°n ƒëang c·∫£m th·∫•y cƒÉng th·∫≥ng. H√£y th·ª≠ k·ªπ thu·∫≠t neo t√¢m l√Ω ƒë∆°n gi·∫£n n√†y:\n\n"
                "Th·ª±c hi·ªán **ba h∆°i th·ªü ch·∫≠m** v√† t·∫≠p trung v√†o nh·ªØng ƒëi·ªÅu b·∫°n *c√≥ th·ªÉ* ki·ªÉm so√°t ngay b√¢y gi·ªù.\n"
                "M·ªôt ƒëi·ªÅu nh·ªè trong t·∫ßm ki·ªÉm so√°t c·ªßa b·∫°n h√¥m nay l√† g√¨? üåø"
            )

        # Habit/addiction
        if any(word in text for word in ["addicted", "habit", "can't stop", "nghi·ªán", "th√≥i quen", "kh√¥ng th·ªÉ d·ª´ng"]):
            return (
                "Ph√° v·ª° th√≥i quen th·∫≠t kh√≥. B·∫Øt ƒë·∫ßu v·ªõi **Ch·∫•p Nh·∫≠n** ‚Äî c√¥ng nh√¢n th√≥i quen "
                "m√† kh√¥ng ph√°n x√©t b·∫£n th√¢n. Sau ƒë√≥ h·ªèi: m·ªôt b∆∞·ªõc *nh·ªè* n√†o b·∫°n c√≥ th·ªÉ th·ª±c hi·ªán h√¥m nay?\n\n"
                "H√£y nh·ªõ: ti·∫øn b·ªô h∆°n ho√†n h·∫£o. üí™"
            )

        # General fallback
        return (
            "T√¥i ·ªü ƒë√¢y ƒë·ªÉ h·ªó tr·ª£ b·∫°n. T√¥i ƒëang g·∫∑p s·ª± c·ªë k·ªπ thu·∫≠t t·∫°m th·ªùi, nh∆∞ng c·∫£m x√∫c c·ªßa b·∫°n l√† th·∫≠t.\n\n"
            "D√†nh m·ªôt ch√∫t th·ªùi gian cho b·∫£n th√¢n ‚Äî c√≥ th·ªÉ ƒëi ra ngo√†i ho·∫∑c th·ª±c hi·ªán m·ªôt v√†i h∆°i th·ªü ch·∫≠m.\n"
            "M·ªôt h√†nh ƒë·ªông chƒÉm s√≥c b·∫£n th√¢n nh·ªè n√†o b·∫°n c√≥ th·ªÉ l√†m ngay b√¢y gi·ªù? üåü"
        )

    # -------------------------------------------------------------------------
    # WhatsApp Formatting
    # -------------------------------------------------------------------------

    def format_whatsapp_message(self, text: str) -> str:
        """Clean and standardize message formatting for WhatsApp."""
        formatted = text.strip()
        formatted = re.sub(r"\n\n\n+", "\n\n", formatted)
        return formatted


# -------------------------------------------------------------------------
# Singleton Instance
# -------------------------------------------------------------------------

_chatbot_instance: Optional[TherapeuticChatbot] = None


def get_chatbot() -> TherapeuticChatbot:
    """Return singleton chatbot instance."""
    global _chatbot_instance

    if _chatbot_instance is None:
        api_key = os.getenv("GOOGLE_API_KEY")

        if not api_key or api_key == "your_google_api_key_here":
            raise ValueError("GOOGLE_API_KEY is not set")

        _chatbot_instance = TherapeuticChatbot(api_key)
        logger.info("Phi√™n b·∫£n Chatbot ƒë√£ ƒë∆∞·ª£c t·∫°o v·ªõi Gemini")

    return _chatbot_instance


# -------------------------------------------------------------------------
# Standalone Test
# -------------------------------------------------------------------------

if __name__ == "__main__":
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
    )

    try:
        chatbot = get_chatbot()
        print("Chatbot ƒë√£ kh·ªüi t·∫°o th√†nh c√¥ng!")
    except Exception as e:
        print(f"L·ªói khi kh·ªüi t·∫°o chatbot: {e}")
